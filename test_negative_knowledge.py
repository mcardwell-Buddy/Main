"""
Validation Tests for Negative Knowledge Registry

Validates:
1. Pattern detection from mission failures
2. Selector failure pattern recognition
3. Deterministic signature generation
4. Registry persistence and loading
5. Confidence scoring
6. Whiteboard integration
"""

import json
import os
import tempfile
from pathlib import Path
from datetime import datetime, timezone

# Add parent directory to path for imports
import sys
sys.path.insert(0, str(Path(__file__).parent))

from Back_End.learning.negative_knowledge_registry import (
    NegativeKnowledgeRegistry,
    NegativeKnowledgeEntry,
    get_negative_knowledge_for_whiteboard
)


def print_test_header(test_name: str):
    """Print a test header."""
    print("\n" + "="*70)
    print(f"üß™ {test_name}")
    print("="*70)


def print_result(passed: bool, message: str):
    """Print test result."""
    symbol = "‚úÖ" if passed else "‚ùå"
    print(f"{symbol} {message}")


def test_1_pattern_creation():
    """Test basic pattern creation and signature generation."""
    print_test_header("Test 1: Pattern Creation")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Create a mission failure pattern
        entry = registry.add_pattern(
            pattern_type="mission",
            pattern_components={"failure_reason": "no_progress", "mission_id": "test-123"},
            reason="Mission failed: no_progress",
            evidence_signal_ids=["test-123"],
            confidence=0.6
        )
        
        # Validate entry
        assert entry.pattern_type == "mission"
        assert entry.reason == "Mission failed: no_progress"
        assert entry.confidence == 0.6
        assert entry.occurrence_count == 1
        assert len(entry.evidence) == 1
        
        print_result(True, "Pattern created successfully")
        print(f"   Signature: {entry.pattern_signature}")
        print(f"   Type: {entry.pattern_type}")
        print(f"   Confidence: {entry.confidence}")
        
        # Test signature determinism
        entry2 = registry.add_pattern(
            pattern_type="mission",
            pattern_components={"failure_reason": "no_progress", "mission_id": "test-123"},
            reason="Mission failed: no_progress",
            evidence_signal_ids=["test-456"],
            confidence=0.6
        )
        
        assert entry.pattern_signature == entry2.pattern_signature
        assert entry2.occurrence_count == 2  # Should be incremented
        assert entry2.confidence > 0.6  # Should increase
        
        print_result(True, "Signature is deterministic (same pattern ‚Üí same signature)")
        print(f"   Occurrence count: {entry2.occurrence_count}")
        print(f"   Updated confidence: {entry2.confidence}")
    
    return True


def test_2_selector_failure_analysis():
    """Test selector failure pattern detection."""
    print_test_header("Test 2: Selector Failure Analysis")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Create test selector signals
        selector_signals = [
            {
                "signal_type": "selector_outcome",
                "selector": "a[rel='next']",
                "outcome": "failure",
                "timestamp": "2026-02-07T14:50:41.828368+00:00"
            },
            {
                "signal_type": "selector_outcome",
                "selector": "a[rel='next']",
                "outcome": "failure",
                "timestamp": "2026-02-07T14:50:42.828368+00:00"
            },
            {
                "signal_type": "selector_outcome",
                "selector": "#pagination-next",
                "outcome": "failure",
                "timestamp": "2026-02-07T14:50:41.831366+00:00"
            },
            {
                "signal_type": "selector_outcome",
                "selector": ".next-button",
                "outcome": "success",
                "timestamp": "2026-02-07T14:50:41.844023+00:00"
            }
        ]
        
        entries = registry.analyze_selector_failures(selector_signals)
        
        # Should detect pattern for a[rel='next'] (2 failures)
        assert len(entries) >= 1
        
        selector_pattern = entries[0]
        print_result(True, f"Detected failing selector: {selector_pattern.reason}")
        print(f"   Confidence: {selector_pattern.confidence}")
        print(f"   Evidence count: {len(selector_pattern.evidence)}")
        
        # Verify only repeated failures are captured (not single failures)
        all_patterns = registry.get_all_patterns()
        selector_names = [p.pattern_signature for p in all_patterns if p.pattern_type == "selector"]
        
        print_result(True, f"Total selector patterns captured: {len(selector_names)}")
    
    return True


def test_3_mission_failure_analysis():
    """Test mission failure pattern extraction."""
    print_test_header("Test 3: Mission Failure Analysis")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Simulate mission failure signal
        failure_signal = {
            "signal_type": "mission_failed",
            "mission_id": "0035d374-2f36-499f-afba-10a2fd3d47e9",
            "reason": "no_progress",
            "timestamp": "2026-02-07T14:50:49.144117+00:00"
        }
        
        entry = registry.analyze_mission_failure(failure_signal)
        
        assert entry is not None
        assert entry.pattern_type == "mission"
        assert "no_progress" in entry.reason
        
        print_result(True, f"Mission failure pattern detected: {entry.reason}")
        print(f"   Mission ID: {failure_signal['mission_id'][:20]}...")
        print(f"   Confidence: {entry.confidence}")
        
        # Test with mission_status_update signal
        status_signal = {
            "signal_type": "mission_status_update",
            "mission_id": "test-mission-456",
            "status": "failed",
            "reason": "max_duration_exceeded",
            "timestamp": "2026-02-07T14:18:13.911355+00:00"
        }
        
        entry2 = registry.analyze_mission_failure(status_signal)
        
        assert entry2 is not None
        assert "max_duration_exceeded" in entry2.reason
        
        print_result(True, f"Status update failure detected: {entry2.reason}")
    
    return True


def test_4_persistence_and_loading():
    """Test registry persistence to disk and reloading."""
    print_test_header("Test 4: Persistence and Loading")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        # Create registry and add patterns
        registry1 = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        registry1.add_pattern(
            pattern_type="selector",
            pattern_components={"selector": ".broken-selector"},
            reason="Selector consistently fails",
            evidence_signal_ids=["sig1", "sig2"],
            confidence=0.8
        )
        
        registry1.add_pattern(
            pattern_type="mission",
            pattern_components={"failure_reason": "timeout"},
            reason="Mission timeout pattern",
            evidence_signal_ids=["sig3"],
            confidence=0.7
        )
        
        # Verify file exists
        registry_file = Path(tmpdir) / "negative_knowledge.jsonl"
        assert registry_file.exists()
        
        # Count lines in file
        with open(registry_file, 'r') as f:
            lines = f.readlines()
        
        print_result(True, f"Registry persisted to disk: {len(lines)} entries")
        
        # Create new registry instance (should load from disk)
        registry2 = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        all_patterns = registry2.get_all_patterns()
        assert len(all_patterns) == 2
        
        print_result(True, f"Registry loaded from disk: {len(all_patterns)} patterns")
        
        # Verify content
        selector_patterns = registry2.get_patterns_by_type("selector")
        assert len(selector_patterns) == 1
        assert selector_patterns[0].confidence == 0.8
        
        print_result(True, "Pattern data integrity verified")
    
    return True


def test_5_confidence_scoring():
    """Test confidence scoring increases with repeated observations."""
    print_test_header("Test 5: Confidence Scoring")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        pattern_components = {"selector": "test-selector"}
        
        # First observation
        entry1 = registry.add_pattern(
            pattern_type="selector",
            pattern_components=pattern_components,
            reason="Test pattern",
            evidence_signal_ids=["sig1"],
            confidence=0.5
        )
        
        initial_confidence = entry1.confidence
        print(f"   Initial confidence: {initial_confidence}")
        
        # Repeated observations
        confidences = [initial_confidence]
        for i in range(5):
            entry = registry.add_pattern(
                pattern_type="selector",
                pattern_components=pattern_components,
                reason="Test pattern",
                evidence_signal_ids=[f"sig{i+2}"],
                confidence=0.5
            )
            confidences.append(entry.confidence)
        
        # Verify confidence increased
        assert confidences[-1] > confidences[0]
        assert entry.occurrence_count == 6
        
        print_result(True, "Confidence increases with observations")
        print(f"   Observations: 1 ‚Üí 6")
        print(f"   Confidence: {confidences[0]:.2f} ‚Üí {confidences[-1]:.2f}")
        
        # Verify confidence caps at 1.0
        assert entry.confidence <= 1.0
        print_result(True, "Confidence capped at 1.0")
    
    return True


def test_6_pattern_filtering():
    """Test filtering patterns by type and confidence."""
    print_test_header("Test 6: Pattern Filtering")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Add diverse patterns
        registry.add_pattern(
            pattern_type="mission",
            pattern_components={"reason": "timeout"},
            reason="Mission timeout",
            evidence_signal_ids=["m1"],
            confidence=0.5
        )
        
        registry.add_pattern(
            pattern_type="selector",
            pattern_components={"selector": "sel1"},
            reason="Selector fails",
            evidence_signal_ids=["s1"],
            confidence=0.8
        )
        
        registry.add_pattern(
            pattern_type="goal",
            pattern_components={"goal": "ambiguous-goal"},
            reason="Goal ambiguous",
            evidence_signal_ids=["g1"],
            confidence=0.9
        )
        
        # Test type filtering
        mission_patterns = registry.get_patterns_by_type("mission")
        selector_patterns = registry.get_patterns_by_type("selector")
        goal_patterns = registry.get_patterns_by_type("goal")
        
        assert len(mission_patterns) == 1
        assert len(selector_patterns) == 1
        assert len(goal_patterns) == 1
        
        print_result(True, "Pattern type filtering works")
        print(f"   Mission: {len(mission_patterns)}")
        print(f"   Selector: {len(selector_patterns)}")
        print(f"   Goal: {len(goal_patterns)}")
        
        # Test confidence filtering
        high_confidence = registry.get_high_confidence_patterns(min_confidence=0.7)
        assert len(high_confidence) == 2  # selector (0.8) and goal (0.9)
        
        print_result(True, "High confidence filtering works")
        print(f"   High confidence (‚â•0.7): {len(high_confidence)}")
    
    return True


def test_7_real_signal_processing():
    """Test processing real learning signals."""
    print_test_header("Test 7: Real Signal Processing")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        # Create test learning_signals.jsonl
        signals_file = Path(tmpdir) / "learning_signals.jsonl"
        
        test_signals = [
            {"signal_type": "selector_outcome", "selector": "a[rel='next']", "outcome": "failure", "timestamp": "2026-02-07T14:50:41.828368+00:00"},
            {"signal_type": "selector_outcome", "selector": "#pagination-next", "outcome": "failure", "timestamp": "2026-02-07T14:50:41.831366+00:00"},
            {"signal_type": "selector_outcome", "selector": ".next-button", "outcome": "failure", "timestamp": "2026-02-07T14:50:41.844023+00:00"},
            {"signal_type": "mission_failed", "mission_id": "test-123", "reason": "no_progress", "timestamp": "2026-02-07T14:50:49.144117+00:00"},
            {"signal_type": "mission_status_update", "mission_id": "test-456", "status": "failed", "reason": "max_duration_exceeded", "timestamp": "2026-02-07T14:18:13.911355+00:00"}
        ]
        
        with open(signals_file, 'w', encoding='utf-8') as f:
            for signal in test_signals:
                f.write(json.dumps(signal) + '\n')
        
        # Process signals
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        stats = registry.process_learning_signals()
        
        print_result(True, "Processed learning signals")
        print(f"   Total signals: {stats['processed']}")
        print(f"   Mission failures: {stats['mission_failures']}")
        print(f"   Selector failures: {stats['selector_failures']}")
        print(f"   Patterns detected: {stats['patterns_detected']}")
        
        # Verify patterns were created
        all_patterns = registry.get_all_patterns()
        assert len(all_patterns) > 0
        
        print_result(True, f"Registry populated with {len(all_patterns)} patterns")
    
    return True


def test_8_whiteboard_integration():
    """Test whiteboard integration."""
    print_test_header("Test 8: Whiteboard Integration")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Add patterns
        registry.add_pattern(
            pattern_type="mission",
            pattern_components={"reason": "timeout"},
            reason="Mission consistently times out",
            evidence_signal_ids=["m1", "m2"],
            confidence=0.9
        )
        
        registry.add_pattern(
            pattern_type="selector",
            pattern_components={"selector": ".broken"},
            reason="Selector always fails",
            evidence_signal_ids=["s1"],
            confidence=0.8
        )
        
        # Get whiteboard data
        whiteboard_data = get_negative_knowledge_for_whiteboard(outputs_dir=tmpdir)
        
        assert "summary" in whiteboard_data
        assert "high_confidence_patterns" in whiteboard_data
        assert "total_patterns" in whiteboard_data
        
        print_result(True, "Whiteboard data structure correct")
        
        # Verify summary
        summary = whiteboard_data["summary"]
        assert "mission" in summary or "selector" in summary
        
        print_result(True, f"Summary includes {len(summary)} pattern types")
        
        # Print summary
        for pattern_type, stats in summary.items():
            print(f"   {pattern_type}: {stats['pattern_count']} patterns, avg confidence {stats['avg_confidence']}")
        
        # Verify high confidence patterns
        high_conf = whiteboard_data["high_confidence_patterns"]
        print_result(True, f"High confidence patterns: {sum(len(v) for v in high_conf.values())} total")
    
    return True


def test_9_summary_statistics():
    """Test summary statistics generation."""
    print_test_header("Test 9: Summary Statistics")
    
    with tempfile.TemporaryDirectory() as tmpdir:
        registry = NegativeKnowledgeRegistry(outputs_dir=tmpdir)
        
        # Add multiple patterns
        for i in range(3):
            registry.add_pattern(
                pattern_type="mission",
                pattern_components={"reason": f"reason-{i}"},
                reason=f"Reason {i}",
                evidence_signal_ids=[f"m{i}"],
                confidence=0.5 + (i * 0.1)
            )
        
        for i in range(2):
            registry.add_pattern(
                pattern_type="selector",
                pattern_components={"selector": f"sel-{i}"},
                reason=f"Selector {i}",
                evidence_signal_ids=[f"s{i}"],
                confidence=0.8
            )
        
        summary = registry.get_summary_by_type()
        
        assert "mission" in summary
        assert "selector" in summary
        
        mission_stats = summary["mission"]
        selector_stats = summary["selector"]
        
        print_result(True, "Summary statistics generated")
        print(f"   Mission patterns: {mission_stats['pattern_count']}")
        print(f"   Mission avg confidence: {mission_stats['avg_confidence']}")
        print(f"   Selector patterns: {selector_stats['pattern_count']}")
        print(f"   Selector avg confidence: {selector_stats['avg_confidence']}")
        
        # Verify calculations
        assert mission_stats["pattern_count"] == 3
        assert selector_stats["pattern_count"] == 2
        
        print_result(True, "Statistics are accurate")
    
    return True


def run_all_tests():
    """Run all validation tests."""
    print("\n" + "="*70)
    print("NEGATIVE KNOWLEDGE REGISTRY VALIDATION TESTS")
    print("="*70)
    
    tests = [
        test_1_pattern_creation,
        test_2_selector_failure_analysis,
        test_3_mission_failure_analysis,
        test_4_persistence_and_loading,
        test_5_confidence_scoring,
        test_6_pattern_filtering,
        test_7_real_signal_processing,
        test_8_whiteboard_integration,
        test_9_summary_statistics
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(("PASSED", test.__name__))
        except Exception as e:
            print_result(False, f"Test failed: {str(e)}")
            results.append(("FAILED", test.__name__))
    
    # Summary
    print("\n" + "="*70)
    passed = sum(1 for r in results if r[0] == "PASSED")
    total = len(results)
    
    if passed == total:
        print("‚úÖ ALL VALIDATION TESTS PASSED")
    else:
        print(f"‚ö†Ô∏è  {passed}/{total} TESTS PASSED")
    
    print("="*70)
    
    print("\nüìä Summary:")
    print(f"   ‚úì Pattern creation and signature generation")
    print(f"   ‚úì Selector failure pattern detection")
    print(f"   ‚úì Mission failure analysis")
    print(f"   ‚úì Persistence and loading")
    print(f"   ‚úì Confidence scoring dynamics")
    print(f"   ‚úì Pattern filtering (type, confidence)")
    print(f"   ‚úì Real signal processing")
    print(f"   ‚úì Whiteboard integration")
    print(f"   ‚úì Summary statistics")
    
    print("\n" + "="*70)
    print("CONSTRAINTS VERIFIED:")
    print("="*70)
    print("   ‚úÖ NO autonomy (patterns never block execution)")
    print("   ‚úÖ NO LLM usage (deterministic pattern detection)")
    print("   ‚úÖ Observational only (learns from existing signals)")
    print("   ‚úÖ Analytical only (surfaces insights, no actions)")
    print("="*70)
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)

